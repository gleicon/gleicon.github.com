<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Drinkin gasoline and wine]]></title>
  <link href="http://gleicon.github.com/atom.xml" rel="self"/>
  <link href="http://gleicon.github.com/"/>
  <updated>2012-03-07T23:38:34-03:00</updated>
  <id>http://gleicon.github.com/</id>
  <author>
    <name><![CDATA[Gleicon]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[On that message queue...]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/07/on-that-message-queue-dot-dot-dot/"/>
    <updated>2012-03-07T06:21:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/07/on-that-message-queue-dot-dot-dot</id>
    <content type="html"><![CDATA[<p>&#8230;that you are trying to do with Redis, the answer is NO.</p>

<p>Not by any issue with <a href="http://redis.io">Redis</a> (which I use in a lot of projects and it&#8217;s a fine piece of software), but because the primitives are not enough to pass as a message broker.</p>

<p>Looking to Redis and <a href="http://www.zeromq.org">ZeroMQ</a> as a message broker in the classic ActiveMQ/RabbitMQ/RestMQ sense is naive, because both are transports (and in Redis case, persistence sometimes) and building blocks that can be attached to systems like these and libraries..</p>

<p>The regular drivers for Redis usually provides no reconnection in case of error or subscribe disconnect, so you probably might end up having your process hanging or if you are lucky, killed with an exception in case of a lost connection. The proper way to do it is to surround Redis with a management layer, as <a href="http://restmq.com">RestMQ</a> or Resque does.</p>

<p>An interesting approach taken on the <a href="https://github.com/fiorix/txredisapi/">twisted redis client</a> is to make use of connection pools which can reconnect. That was the single feature that made RestMQ possible. <a href="https://github.com/ask/kombu">Kombu</a> connections follow the same pattern, abstracting fan outs and routes over a connection pool to Redis, the simples fallback in case you dont want to install any other complex message broker.</p>

<p>Applying only to pub/sub channels without fallback is not a good idea specially if you rely on multiple consumers. On the other hand, for simple one-time no-distributed-locks messaging (as with udp multicas or service discovery), it might be a good choice because: a) there is no persistence and b) if the transport is not available, the processes(or agents) are idle.</p>

<p>The fine line here is the direction of the messages. In a exchange environment, the broker plays the good part of managing the transport shortcomings. On a fire and forget which the messages are importante, the broker helps to keep the message somewhere until it&#8217;s fetched. Fire and forget of disposable messages might be a good choice to do it if there is no immediate action to be taken and if there is some kind of retransmission/expiring on the sender part. Remember the SMTP protocol.</p>

<p>That&#8217;s not even touching the cases where a message queue is used as a kind of distributed lock where only one of many similar consumers might get a message, instead of a broadcast scenario.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[memcached backend engines]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/06/memcached-backend-engines/"/>
    <updated>2012-03-06T14:31:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/06/memcached-backend-engines</id>
    <content type="html"><![CDATA[<p>The memcached protocol is very known and implemented on many languages and frameworks. Its primitives are based around getting and setting values that internally are mapped to keys.</p>

<p>There are two kinds of protocol: ascii and binary. The recommended protocol is the binary protocol, which is modern and has room for new features.</p>

<p>I&#8217;ve been trying my hand at some memcached servers implementations in python, based on twisted and gevent, but looking for some answers regarding the protocol answer, I got a tip that the original memcached server is supporting backend engines through an ANSI C interface. In an insomniac week end I was able to hack around two examples: a filesystem based store and a redis based store.</p>

<p>The <a href="https://github.com/gleicon/memcached_fs_engine">filesystem engine</a> was based entirely on @trondn <a href="http://trondn.blogspot.com/2010/10/writing-your-own-storage-engine-for.html">tutorial</a>. <a href="https://github.com/gleicon/memcached_redis_engine">The Redis engine</a> I made based on my original plan for a <a href="https://github.com/gleicon/tx-memcached-redis">python based memcached server</a>. I&#8217;ve used Redis&#8217; hashes to store data and attributes for each memcached key.</p>

<p>To create the hash, the engine issues a command like this:</p>

<blockquote><p>HMSET <keyname> key <keyname> nkey <keyname len> data <data> ndata <data len> flags <flags> exptime <expiration time, if any></p></blockquote>

<p>The advantage of Redis commands being atomic is that INCR, DECR and methods like this are a given. It was a matter of using hiredis to map the right commands. One thing that I&#8217;d do differently is to implement a kind of connection pool and configuration options.</p>

<p>To test the backend compliance to the binary protocol I&#8217;ve used <em>memcapable</em>, which usually comes bundled with memcached. The engine must be compiled as a dynamic library so it can be loaded as memcached -E engine.so.</p>

<p>One of the things that I think that having a configurable memcached frontend is good for is to capture metrics. As many frameworks already have a memcached client, it&#8217;s easy to create an instance and increment/decrement counters on it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Agents and Event Listeners for Python]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/04/agents-and-event-listeners-for-python/"/>
    <updated>2012-03-04T19:03:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/04/agents-and-event-listeners-for-python</id>
    <content type="html"><![CDATA[<p>When modeling a distributed system one might stumble in the Actor model, implemented in one way or another - be it natively on Erlang or a complete library as Akka.</p>

<p>There is a lot of discussion over concurrency models, but regardless the Actor model serves well to break a task between different processes/servers.</p>

<p>Built usually over a messaging channel, these frameworks are usually adapted for a set of tasks.
As it wouldn&#8217;t be different, some of them had a lot more than I needed, and the frameworks for Python were divided between trying to reimplement Akka or completely different concept.</p>

<p>I took some time out to build <a href="http://github.com/gleicon/mure">Mure</a> to learn more about kombu, a multi-transport library for python. It&#8217;s a really simple actor library.</p>

<div><script src='https://gist.github.com/1975450.js?file='></script>
<noscript><pre><code>   from mure.core import connect, disconnect, worker, send_message             
    from time import sleep                                                      
                                                                                
    @worker('/workers/delicious')                                               
    def a_worker(message):                                                      
        print &quot;received: %s&quot; % message                                          
        send_message('/workers/jazz', 'd-d-d-dance')                            
                                                                                
    @worker('/workers/jazz')                                                    
    def another_worker(message):                                                
        print &quot;received2: %s&quot; % message                                         
        send_message('/workers/delicious', &quot;saaaap&quot;)                            
                                                                                
    @worker('/workers/delicious')                                               
    def third_worker(message):                                                  
        print &quot;the other worker received: %s&quot; % message                         
                                                                                
    if __name__ == &quot;__main__&quot;:                                                  
        connect()                                                               
        send_message('/workers/jazz', 'let it start')                           
        sleep(1)                                                                
        disconnect()      </code></pre></noscript></div>


<p>The decorator @worker() says that each time that a message to the queue named after the string arrives, the function might be executed having the message as parameter.</p>

<p><img src="images/mure_architecture.png" title="Architecture for Mure" ></p>

<p>After fidling with <a href="https://github.com/jesusabdullah/pyee">pyee</a>, I&#8217;ve implemented an EventEmitter on top of it. The syntax is the same as node.js, but it&#8217;s a distributed event emitter.</p>

<div><script src='https://gist.github.com/1975438.js?file='></script>
<noscript><pre><code>from mure.dee import DistEventEmitter                                                                                                                                             
import os, json, time                                                           
from gevent import sleep, spawn                                                 
                                                                                
dbus = DistEventEmitter()                                                       
                                                                                
def producer():                                                                 
    count =0                                                                    
    while(True):                                                                
        count = count +1                                                        
        print count                                                             
        dbus.emit(&quot;message&quot;, &quot;hnam %d&quot; % count)                                 
        sleep(5)                                                                
                                                                                
                                                                                
def join_listener(msg):                                                         
    print &quot;%s&quot; % msg                                                            
                                                                                
def msg_listener(msg):                                                          
    print &quot;received message: %s&quot; % msg                                          
                                                                                
def main():                                                                     
    dbus.emit('join', &quot;oeam&quot;)                                                   
    dbus.on('message', msg_listener)                                            
    producer()                                                                  
                                                                                
if __name__ == &quot;__main__&quot;:                                                      
    main()</code></pre></noscript></div>


<p><img src=http://localhost:8080/track?_id=1 width=1 height=1></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Riemann client for python]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/04/reimann-client-for-python/"/>
    <updated>2012-03-04T18:34:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/04/reimann-client-for-python</id>
    <content type="html"><![CDATA[<p>In the search for the right backend to implement a metrics suited to my projects, I saw that <a href="http://aphyr.github.com/riemann">Riemann</a> (event server built on Closure) would save time by already having all kinds of math related to means, percentiles and a flexible configuration.</p>

<p>The protocol uses Google&#8217;s Protocol Buffers, but it&#8217;s very simple (I was able to go from 0 to a simple driver in less than 4 hours - including the protobuf part).
Basic functionality as sending metrics and querying are ready, but the driver still needs polishing - include a connection pool, and a twisted version. As it is right now, it works great with gevent apps.</p>

<p>A basic send/query app would be like this:</p>

<div><script src='https://gist.github.com/1975656.js?file='></script>
<noscript><pre><code>from riemann import RiemannClient                                                                                                                                                 
                                                                                
def main():                                                                     
    rc = RiemannClient()                                                        
    rc.send({'host':'127.0.0.1', 'service': 'www', 'state': 'down', 'metric_f': 10000})
    res = rc.query('host')                                                      
    print res                                                                   
    for e in res.events: print e.host                                           
                                                                                
if __name__ == '__main__':                                                      
    main()     </code></pre></noscript></div>


<p>It supports both tcp and udp transports and includes the proper classes translated from protobuf spec to python. Requires google&#8217;s protobuf library. The repo is on github <a href="https://github.com/gleicon/pyriemann">pyriemann</a>. There is an examples directory with riemann_health.py, translated from the ruby version to python.</p>
]]></content>
  </entry>
  
</feed>
