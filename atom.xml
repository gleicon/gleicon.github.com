<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Drinkin gasoline and wine]]></title>
  <link href="http://gleicon.github.com/atom.xml" rel="self"/>
  <link href="http://gleicon.github.com/"/>
  <updated>2012-06-07T23:59:22-03:00</updated>
  <id>http://gleicon.github.com/</id>
  <author>
    <name><![CDATA[Gleicon]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Python and GEvent]]></title>
    <link href="http://gleicon.github.com/blog/2012/06/07/python-and-gevent/"/>
    <updated>2012-06-07T23:36:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/06/07/python-and-gevent</id>
    <content type="html"><![CDATA[<p>The last post took some time over <a href="http://cyclone.io">cyclone</a> and it wasn&#8217;t fair that I&#8217;ve mentioned gevent briefly. I&#8217;ve have been using this library both for quick prototypes, production code and system upgrades. It&#8217;s not an instant-evented-magic-to-crappy-code but it provides simple and solid primitives such as greenlets that enable the use of good libraries in a fashion manner.</p>

<p>For instance, the great kombu library, which provides abstraction over different messaging protocols is not available to twisted. Worst yet, the txAMQP library is not straight forward to use. At the <a href="http://github.com/gleicon/mure">mure</a> project I wanted to come with a quick and simple agent network that communicated for a shared bus. I wasn&#8217;t worried about which kind of channel as long as I could prototype and run it quickly. It proved good because in short time I&#8217;ve implemented an EventEmitter clone inspired on node.js and a few days ago a bridge between python and node.js event emitters.</p>

<p>It could be done using twisted but I would have to shave the yak related to a common multi broker messaging or stick to a single message broker. Not a problem if I had it clear from the start what I wanted it to be. But having gevent helped a lot to leverage the common blocking libraries and to use greenlets as a thread abstraction.</p>

<figure class='code'><figcaption><span>mure/core.py </span><a href='https://github.com/gleicon/mure/blob/master/mure/core.py#L19-37'>link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'>    <span class="k">def</span> <span class="nf">add_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">workername</span><span class="p">,</span> <span class="n">callback</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">[</span><span class="n">workername</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>
</span><span class='line'>        <span class="k">def</span> <span class="nf">_listener</span><span class="p">():</span>
</span><span class='line'>            <span class="n">qname</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">(</span><span class="n">workername</span><span class="p">,</span> <span class="n">Exchange</span><span class="p">(</span><span class="s">&quot;exchange:</span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">workername</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s">&#39;fanout&#39;</span><span class="p">))</span>
</span><span class='line'>            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connected</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span>
</span><span class='line'>                <span class="k">print</span> <span class="s">&quot;waiting </span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connected</span>
</span><span class='line'>                <span class="n">gevent</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>            <span class="k">with</span> <span class="n">BrokerConnection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_transport_url</span><span class="p">)</span> <span class="k">as</span> <span class="n">conn</span><span class="p">:</span>
</span><span class='line'>                <span class="k">with</span> <span class="n">conn</span><span class="o">.</span><span class="n">SimpleQueue</span><span class="p">(</span><span class="n">qname</span><span class="p">)</span> <span class="k">as</span> <span class="n">queue</span><span class="p">:</span>
</span><span class='line'>                    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class='line'>                        <span class="k">try</span><span class="p">:</span>
</span><span class='line'>                            <span class="n">message</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span class='line'>                            <span class="k">if</span> <span class="n">message</span><span class="p">:</span>
</span><span class='line'>                                <span class="bp">self</span><span class="o">.</span><span class="n">_execute_callbacks</span><span class="p">(</span><span class="n">workername</span><span class="p">,</span> <span class="n">message</span><span class="o">.</span><span class="n">payload</span><span class="p">)</span>
</span><span class='line'>                                <span class="n">message</span><span class="o">.</span><span class="n">ack</span><span class="p">()</span>
</span><span class='line'>                                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connected</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span> <span class="k">break</span>
</span><span class='line'>                        <span class="k">except</span><span class="p">:</span>
</span><span class='line'>                            <span class="k">pass</span>
</span><span class='line'>        <span class="n">gevent</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">_listener</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The last line spawn the function <em>_listener</em> which binds into an exchange queue. Each of these listeners take care of a communication channel and execute the callbacks associated to that worker name. Exchange, queue, worker are the samething applied in different contexts. These workers (@worker(&#8216;name_of_worker&#8217;)) are stored in a hash, each item a list of listeners. This spans out the messages around the right recipients.</p>

<p>Another great gevent companion is <a href="http://bottlepy.org/">bottle</a>, a DSL for web programming. Its interface is clean and combining with gevent lets you quickly come with thin webservices interfaces. I&#8217;ve create an application called <a href="https://github.com/gleicon/uurl">uurl</a> - an url shortener, entirely based on gevent, bottle and readis. I&#8217;ve set to rewrite it from time to time, on different languages and frameworks to get a hang of their components and so far this is the cleanest implementation. It started as an WSGI service and later I&#8217;ve converted to gevent by simply changing servers, monkey patching all and using a redis connection pool.</p>

<p>Monkey patching is a technique that bottle uses to convert the original socket, threads and other python modules to be non-blocking using its greenlets and I/O loop, in a way that the code change is minimal from a blocking application.</p>

<figure class='code'><figcaption><span>uurl.py </span><a href='https://github.com/gleicon/uurl/blob/master/uurl.py#L120-125'>link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">GEventServerAdapter</span><span class="p">(</span><span class="n">ServerAdapter</span><span class="p">):</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">handler</span><span class="p">):</span>
</span><span class='line'>        <span class="kn">from</span> <span class="nn">gevent</span> <span class="kn">import</span> <span class="n">monkey</span>
</span><span class='line'>        <span class="n">monkey</span><span class="o">.</span><span class="n">patch_socket</span><span class="p">()</span>
</span><span class='line'>        <span class="kn">from</span> <span class="nn">gevent.wsgi</span> <span class="kn">import</span> <span class="n">WSGIServer</span>
</span><span class='line'>        <span class="n">WSGIServer</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">host</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">port</span><span class="p">),</span> <span class="n">handler</span><span class="p">)</span><span class="o">.</span><span class="n">serve_forever</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>To close this post, I&#8217;d like to add that I usually compare this setup with Ruby/Sinatra/Thin. As a derivative of <a href="http://restmq.com">RestMQ</a> I&#8217;ve created <a href="https://github.com/gleicon/tinymq">TinyMQ</a> - a set of small implementations of RestMQ core ideas. This is a subject for another post but the whole message broker ran on less than 100 lines <a href="https://github.com/gleicon/tinymq/blob/master/python/tinymq.py">tinymq.py</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cyclone - a twisted based Tornado implementation]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/15/cyclone-a-twisted-based-tornado-implementation/"/>
    <updated>2012-03-15T23:21:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/15/cyclone-a-twisted-based-tornado-implementation</id>
    <content type="html"><![CDATA[<h3>Overview</h3>

<p>Some time ago, a company called FriendFeed released <a href="http://www.tornadoweb.org/">Tornado</a>, a neat web application server for python. After some press and unquestionable results it was discussed whether it should have used the Twisted Framework foundation instead of implementing a new ioloop. Long history short, Tornado shares some similarities with <a href="http://twistedmatrix.com/trac/">Twisted</a>, but the programming API is better looking than twisted.web.</p>

<p>After some trials by different people <a href="http://github.com/fiorix">Alex Fiori</a> forked Tornado and bundled it with a Twisted backend and some other goodies - calling it <a href="http://cyclone.io">cyclone</a>. After a while I started using it to build <a href="http://restmq.com">RestMQ</a> and started contributing code for WebSockets and other drivers. There is a lot of sense in combining both worlds as Twisted has an extensive ibrary of protocols and clients, a well defined programming model (like it or not, based on deferreds/futures and generators) and mature cross-platform ioloop implementation. Cyclone&#8217;s gettext implementation was merged back some time in the past and we constantly merge from upstream on interesting features.</p>

<p>I do most of my coding in python splitting time between cyclone and gevent and right now I gotta say that cyclone has great features that compete in terms of productivity with Tornado.</p>

<p>Code that is build on tornado will run easily after correcting the package names. On the parts related to ioloop, there are the same mapped functionality on twisted - such as timers and pools. To build new protocols you can leverage LineProtocol and other interesting tx classes. The best part is taking advantage of drivers. In an evented loop, if you use a regular driver that can block (pause while waiting for an answer from network or heavy calculation) the other operations are also halted.</p>

<p>If you have a defined programming model to deal with it (which both tornado and twisted defined), it is a matter of yielding at the right moment or using a deferred return to realize the result of the operation later. That can lead to a kind of callback hell both for reading code and profiling it but there are few abstractions that will go far away from it.</p>

<h3>Interesting Cyclone features</h3>

<p><img src="images/cyclone_arch.png" title="Cyclone Architecture" ></p>

<p>Tornado core (ioloop) was changed by a twisted based factory which yield the right reactor. Over this structure the protocol implementation and clients were adapted to use it with minimal to none interface changes.</p>

<p>The most affected module initially was cyclone.web but the whole structure changed and got bundled drivers as mongodb, redis, sqlite and protocols as XMLRPC, JSONRPC, websockets and sse. There is an email module already which can serve as template-to-message app, based on TwistedMail. All these features are natively asynchronous.</p>

<p>Beyond that, a cyclone app is a twisted protocol and can take advantage of the surrounding structure as plugins and PyDirector/cpu affinity. It was easy to merge or create due to the synergy based on already existing twisted applications. There is also an application skeleton and a minimal bottle.py DSL port - both allowing for quickstart web applications.</p>

<p>Much of the authentication and authorization is done over decorators, allowing for clean code - along with the inline deferreds:</p>

<pre><code>class IndexHandler(cyclone.web.RequestHandler):
    @cyclone.web.authenticated  # triggers authentication
    @defer.inlineCallbacks      # allows for inline callbacks
    def get(self):
        result = yield self.do_download()  # inline callback, no need to explicitly added 
        self.write(result)
</code></pre>

<p>That alone may help on the callback spaghetti but it keeps being twisted.</p>

<h3>Evented I/O intermission - is it faster ?</h3>

<p>No. It&#8217;s just a choice of multiplexer to allow for better time utilization. It helps scaling better the same resources as other approaches such as greenlets over an evented loop (gevent). The most important thing to note is that they are not a substitute for threads of VM limitations. My setups usually are 1 or 2 instances per core, with affinity and a load balance in front of them. This can be done in a different manner as using threadpools or even processes.</p>

<p>Last year I presented at Sao Paulo Perl Workshop and OSCon on this subject and the feedback that I got is that most of the time the very application gets complex so the matter of evented I/O ends up being one of the things that shapes these changes (for good or bad) but not the safeguard or guarantee that the quality will keep up.</p>

<div class="embed rich SlideShare"><div style="width:425px" id="__ss_7883101"> <strong style="display:block;margin:12px 0 4px"><a href="http://www.slideshare.net/gleicon/architecture-by-accident" title="Architecture by Accident" target="_blank">Architecture by Accident</a></strong> <iframe src="http://www.slideshare.net/slideshow/embed_code/7883101" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0" allowfullscreen></iframe> <div style="padding:5px 0 12px"> View more <a href="http://www.slideshare.net/" target="_blank">presentations</a> from <a href="http://www.slideshare.net/gleicon" target="_blank">gleicon</a> </div> </div></div>




<div class="embed rich SlideShare"><div style="width:425px" id="__ss_8728812"> <strong style="display:block;margin:12px 0 4px"><a href="http://www.slideshare.net/gleicon/oscon-performance-vs-scalability" title="OSCon - Performance vs Scalability" target="_blank">OSCon - Performance vs Scalability</a></strong> <iframe src="http://www.slideshare.net/slideshow/embed_code/8728812" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0" allowfullscreen></iframe> <div style="padding:5px 0 12px"> View more <a href="http://www.slideshare.net/thecroaker/death-by-powerpoint" target="_blank">PowerPoint</a> from <a href="http://www.slideshare.net/gleicon" target="_blank">gleicon</a> </div> </div></div>


<h3>EOF</h3>

<p>Check the <a href="https://github.com/fiorix/cyclone">code</a> and try it for yourself. I consider that using cyclone is a good and gentle intro to twisted as it sets a clear objective over web applications. There are plenty of good code at the demos directory and the app skeleton already comes up with a bootstrap.css based application boilerplate. Also, send patches.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On that message queue...]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/07/on-that-message-queue-dot-dot-dot/"/>
    <updated>2012-03-07T06:21:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/07/on-that-message-queue-dot-dot-dot</id>
    <content type="html"><![CDATA[<p>&#8230;that you are trying to do with Redis, the answer is NO.</p>

<p>Not by any issue with <a href="http://redis.io">Redis</a> (which I use in a lot of projects and it&#8217;s a fine piece of software), but because the primitives are not enough to pass as a message broker.</p>

<p>Looking to Redis and <a href="http://www.zeromq.org">ZeroMQ</a> as a message broker in the classic ActiveMQ/RabbitMQ/RestMQ sense is naive, because both are transports (and in Redis case, persistence sometimes) and building blocks that can be attached to systems like these and libraries..</p>

<p>The regular drivers for Redis usually provides no reconnection in case of error or subscribe disconnect, so you probably might end up having your process hanging or if you are lucky, killed with an exception in case of a lost connection. The proper way to do it is to surround Redis with a management layer, as <a href="http://restmq.com">RestMQ</a> or Resque does.</p>

<p>An interesting approach taken on the <a href="https://github.com/fiorix/txredisapi/">twisted redis client</a> is to make use of connection pools which can reconnect. That was the single feature that made RestMQ possible. <a href="https://github.com/ask/kombu">Kombu</a> connections follow the same pattern, abstracting fan outs and routes over a connection pool to Redis, the simples fallback in case you dont want to install any other complex message broker.</p>

<p>Applying only to pub/sub channels without fallback is not a good idea specially if you rely on multiple consumers. On the other hand, for simple one-time no-distributed-locks messaging (as with udp multicas or service discovery), it might be a good choice because: a) there is no persistence and b) if the transport is not available, the processes(or agents) are idle.</p>

<p>The fine line here is the direction of the messages. In a exchange environment, the broker plays the good part of managing the transport shortcomings. On a fire and forget which the messages are importante, the broker helps to keep the message somewhere until it&#8217;s fetched. Fire and forget of disposable messages might be a good choice to do it if there is no immediate action to be taken and if there is some kind of retransmission/expiring on the sender part. Remember the SMTP protocol.</p>

<p>That&#8217;s not even touching the cases where a message queue is used as a kind of distributed lock where only one of many similar consumers might get a message, instead of a broadcast scenario.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[memcached backend engines]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/06/memcached-backend-engines/"/>
    <updated>2012-03-06T14:31:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/06/memcached-backend-engines</id>
    <content type="html"><![CDATA[<p>The memcached protocol is very known and implemented on many languages and frameworks. Its primitives are based around getting and setting values that internally are mapped to keys.</p>

<p>There are two kinds of protocol: ascii and binary. The recommended protocol is the binary protocol, which is modern and has room for new features.</p>

<p>I&#8217;ve been trying my hand at some memcached servers implementations in python, based on twisted and gevent, but looking for some answers regarding the protocol answer, I got a tip that the original memcached server is supporting backend engines through an ANSI C interface. In an insomniac week end I was able to hack around two examples: a filesystem based store and a redis based store.</p>

<p>The <a href="https://github.com/gleicon/memcached_fs_engine">filesystem engine</a> was based entirely on @trondn <a href="http://trondn.blogspot.com/2010/10/writing-your-own-storage-engine-for.html">tutorial</a>. <a href="https://github.com/gleicon/memcached_redis_engine">The Redis engine</a> I made based on my original plan for a <a href="https://github.com/gleicon/tx-memcached-redis">python based memcached server</a>. I&#8217;ve used Redis&#8217; hashes to store data and attributes for each memcached key.</p>

<p>To create the hash, the engine issues a command like this:</p>

<blockquote><p>HMSET <keyname> key <keyname> nkey <keyname len> data <data> ndata <data len> flags <flags> exptime <expiration time, if any></p></blockquote>

<p>The advantage of Redis commands being atomic is that INCR, DECR and methods like this are a given. It was a matter of using hiredis to map the right commands. One thing that I&#8217;d do differently is to implement a kind of connection pool and configuration options.</p>

<p>To test the backend compliance to the binary protocol I&#8217;ve used <em>memcapable</em>, which usually comes bundled with memcached. The engine must be compiled as a dynamic library so it can be loaded as memcached -E engine.so.</p>

<p>One of the things that I think that having a configurable memcached frontend is good for is to capture metrics. As many frameworks already have a memcached client, it&#8217;s easy to create an instance and increment/decrement counters on it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Agents and Event Listeners for Python]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/04/agents-and-event-listeners-for-python/"/>
    <updated>2012-03-04T19:03:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/04/agents-and-event-listeners-for-python</id>
    <content type="html"><![CDATA[<p>When modeling a distributed system one might stumble in the Actor model, implemented in one way or another - be it natively on Erlang or a complete library as Akka.</p>

<p>There is a lot of discussion over concurrency models, but regardless the Actor model serves well to break a task between different processes/servers.</p>

<p>Built usually over a messaging channel, these frameworks are usually adapted for a set of tasks.
As it wouldn&#8217;t be different, some of them had a lot more than I needed, and the frameworks for Python were divided between trying to reimplement Akka or completely different concept.</p>

<p>I took some time out to build <a href="http://github.com/gleicon/mure">Mure</a> to learn more about kombu, a multi-transport library for python. It&#8217;s a really simple actor library.</p>

<div><script src='https://gist.github.com/1975450.js?file='></script>
<noscript><pre><code>   from mure.core import connect, disconnect, worker, send_message             
    from time import sleep                                                      
                                                                                
    @worker('/workers/delicious')                                               
    def a_worker(message):                                                      
        print &quot;received: %s&quot; % message                                          
        send_message('/workers/jazz', 'd-d-d-dance')                            
                                                                                
    @worker('/workers/jazz')                                                    
    def another_worker(message):                                                
        print &quot;received2: %s&quot; % message                                         
        send_message('/workers/delicious', &quot;saaaap&quot;)                            
                                                                                
    @worker('/workers/delicious')                                               
    def third_worker(message):                                                  
        print &quot;the other worker received: %s&quot; % message                         
                                                                                
    if __name__ == &quot;__main__&quot;:                                                  
        connect()                                                               
        send_message('/workers/jazz', 'let it start')                           
        sleep(1)                                                                
        disconnect()      </code></pre></noscript></div>


<p>The decorator @worker() says that each time that a message to the queue named after the string arrives, the function might be executed having the message as parameter.</p>

<p><img src="images/mure_architecture.png" title="Architecture for Mure" ></p>

<p>After fidling with <a href="https://github.com/jesusabdullah/pyee">pyee</a>, I&#8217;ve implemented an EventEmitter on top of it. The syntax is the same as node.js, but it&#8217;s a distributed event emitter.</p>

<div><script src='https://gist.github.com/1975438.js?file='></script>
<noscript><pre><code>from mure.dee import DistEventEmitter                                                                                                                                             
import os, json, time                                                           
from gevent import sleep, spawn                                                 
                                                                                
dbus = DistEventEmitter()                                                       
                                                                                
def producer():                                                                 
    count =0                                                                    
    while(True):                                                                
        count = count +1                                                        
        print count                                                             
        dbus.emit(&quot;message&quot;, &quot;hnam %d&quot; % count)                                 
        sleep(5)                                                                
                                                                                
                                                                                
def join_listener(msg):                                                         
    print &quot;%s&quot; % msg                                                            
                                                                                
def msg_listener(msg):                                                          
    print &quot;received message: %s&quot; % msg                                          
                                                                                
def main():                                                                     
    dbus.emit('join', &quot;oeam&quot;)                                                   
    dbus.on('message', msg_listener)                                            
    producer()                                                                  
                                                                                
if __name__ == &quot;__main__&quot;:                                                      
    main()</code></pre></noscript></div>


<p><img src=http://localhost:8080/track?_id=1 width=1 height=1></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Riemann client for python]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/04/reimann-client-for-python/"/>
    <updated>2012-03-04T18:34:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/04/reimann-client-for-python</id>
    <content type="html"><![CDATA[<p>In the search for the right backend to implement a metrics suited to my projects, I saw that <a href="http://aphyr.github.com/riemann">Riemann</a> (event server built on Closure) would save time by already having all kinds of math related to means, percentiles and a flexible configuration.</p>

<p>The protocol uses Google&#8217;s Protocol Buffers, but it&#8217;s very simple (I was able to go from 0 to a simple driver in less than 4 hours - including the protobuf part).
Basic functionality as sending metrics and querying are ready, but the driver still needs polishing - include a connection pool, and a twisted version. As it is right now, it works great with gevent apps.</p>

<p>A basic send/query app would be like this:</p>

<div><script src='https://gist.github.com/1975656.js?file='></script>
<noscript><pre><code>from riemann import RiemannClient                                                                                                                                                 
                                                                                
def main():                                                                     
    rc = RiemannClient()                                                        
    rc.send({'host':'127.0.0.1', 'service': 'www', 'state': 'down', 'metric_f': 10000})
    res = rc.query('host')                                                      
    print res                                                                   
    for e in res.events: print e.host                                           
                                                                                
if __name__ == '__main__':                                                      
    main()     </code></pre></noscript></div>


<p>It supports both tcp and udp transports and includes the proper classes translated from protobuf spec to python. Requires google&#8217;s protobuf library. The repo is on github <a href="https://github.com/gleicon/pyriemann">pyriemann</a>. There is an examples directory with riemann_health.py, translated from the ruby version to python.</p>
]]></content>
  </entry>
  
</feed>
