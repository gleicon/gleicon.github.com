<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Drinkin gasoline and wine]]></title>
  <link href="http://gleicon.github.com/atom.xml" rel="self"/>
  <link href="http://gleicon.github.com/"/>
  <updated>2013-01-01T18:19:16-02:00</updated>
  <id>http://gleicon.github.com/</id>
  <author>
    <name><![CDATA[Gleicon]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Metrics]]></title>
    <link href="http://gleicon.github.com/blog/2013/01/01/metrics/"/>
    <updated>2013-01-01T18:04:00-02:00</updated>
    <id>http://gleicon.github.com/blog/2013/01/01/metrics</id>
    <content type="html"><![CDATA[<p>This holiday I&#8217;ve released two new projects at my github repository: PyMetrics and TxMetrics. There are metrics libraries inspired by Coda Hale&#8217;s Metric project [http://metrics.codahale.com/]. Although not that complete, I&#8217;ve ported what I feel that I was repeating myself in my projects and what I lacked to python and the twisted framework.</p>

<p>Some months ago, I&#8217;ve ported a <a href="https://github.com/gleicon/py_descriptive_statistics">descriptive stats library to python</a> and also integrated it into PyMetrics and TxMetrics. These libraries are backed by redis and I intend to release a port to ruby using the same underlying data structures.</p>

<p>Most of the applications have at least one form of counter spread around it. My intention was to use the same semantic for these situations and also introduce new ways to measure data that is not bound to standard monitoring software extracting data from TCP ports or log files.</p>

<p>The difference between them is that I&#8217;ve had to port the tradicional python approach to twisted using the deferred constructs and another library that I contribute to, txredisapi.</p>

<p>With these libraries you can extract data realtime from your application and go from monitoring to dashboards, which is the next step I&#8217;m planning with the ruby client: to integrate with <a href="https://github.com/Shopify/dashing">Dashing</a></p>

<p>Links:</p>

<ul>
<li><a href="https://github.com/gleicon/txmetrics">TxMetrics</a></li>
<li><a href="https://github.com/gleicon/pymetrics">PyMetrics</a></li>
<li><a href="https://github.com/gleicon/py_descriptive_statistics">Python Descriptive Statistics</a></li>
<li><a href="https://github.com/fiorix/txredisapi">TxRedisAPI</a></li>
<li><a href="https://github.com/Shopify/dashing">Dashing</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ye Olde Devops notes and links]]></title>
    <link href="http://gleicon.github.com/blog/2013/01/01/ye-olde-devops-notes-and-links/"/>
    <updated>2013-01-01T17:36:00-02:00</updated>
    <id>http://gleicon.github.com/blog/2013/01/01/ye-olde-devops-notes-and-links</id>
    <content type="html"><![CDATA[<h4>Note: this is an old post that I&#8217;ve had for months in my pipeline waiting for another project.</h4>

<h3>late night chats with cv - intended to be published somewhere at it&#8217;s never Lispus</h3>

<p>This a summary of a gtalk chat on a deploy/keep it simple workflow w/o touching on devops or any other diatribes. Mostly interesting links and notes I&#8217;ve extracted from the chat history.</p>

<p>@cv + @gleicon</p>

<h3>using http and memcached as messaging protocols</h3>

<ul>
<li>clients everywhere</li>
<li>sanitize following their rules (http timeouts/memcached keys)</li>
<li>they are not transports so short messages</li>
<li>pool strategies (more than one connection)</li>
<li>reconnect strategies</li>
</ul>


<h3>using lxc and rootfs images</h3>

<ul>
<li>rootfs can run on KVM and LXC (probably vbox ?)</li>
<li>vagrant/simplestack to interface to local/external VMs (would need to patch vagrant, etc)</li>
<li>use ubuntu/whatever new image with all bundled software</li>
</ul>


<h3>package when tagged</h3>

<ul>
<li>bricklayer/fpm/rpmbuild/etc</li>
<li>deploy images around before committing to production release</li>
<li>no need for conf management if the image is already loaded</li>
</ul>


<h3>good images</h3>

<ul>
<li>new software</li>
<li>redis/memcached up and running at localhost</li>
<li>few configuration items (localhost or ENV var)</li>
<li>use buildpacks</li>
<li>bake images with packaged + tagged production version, distribute over nginx</li>
</ul>


<h3>deploy</h3>

<ul>
<li>fetch images</li>
<li>deploy on VMs/LXC</li>
<li>instrument images with watchdog agent</li>
<li>messages over queue/http queue/pubsub</li>
<li>one server lost -> spin new server</li>
<li>loadbalancer ?</li>
<li>monitoring: riemann for real distributed stuff/uptime for local</li>
</ul>


<h3>links</h3>

<ul>
<li>https://github.com/cv/escape-server-config (config server management)</li>
<li>https://github.com/locaweb/bricklayer (packaging app server)</li>
<li>http://www.stgraber.org/2012/03/04/booting-an-ubuntu-12-04-virtual-machine-in-an-lxc-container/ (linux containers)</li>
<li>https://github.com/locaweb/simplestack (hypervisor api)</li>
<li>http://vagrantup.com/</li>
<li>http://blog.heroku.com/archives/2012/7/17/buildpacks/</li>
<li>https://github.com/ddollar/mason (buildpack automation)</li>
<li>https://github.com/peterkeen/dokuen (mini paas)</li>
<li>https://github.com/ddollar/foreman (app control)</li>
<li>https://github.com/fzaninotto/uptime (uptime monitoring)</li>
<li>http://www.openresty.org/ (nginx +lua + redis dynamic vhost)</li>
<li>http://graylog2.org/</li>
<li>https://github.com/locaweb/logix (graylog2 syslog -> amqp for graylog2)</li>
<li>https://github.com/gleicon/python_dns_servers (possible dynamic dns)&#8217;</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tab sink for the end of 2012]]></title>
    <link href="http://gleicon.github.com/blog/2013/01/01/tab-sink-for-the-end-of-2012/"/>
    <updated>2013-01-01T17:35:00-02:00</updated>
    <id>http://gleicon.github.com/blog/2013/01/01/tab-sink-for-the-end-of-2012</id>
    <content type="html"><![CDATA[<h4>Note: this is an old post that I&#8217;ve had for months in my pipeline waiting for another project</h4>

<h4>The tab sink for the end of 2012 (originally I started this post Oct 20 2012)</h4>

<p>Most of these stuff were on my tabs for the whole week (and even weeks before that) and just now I managed to filter and check them.</p>

<ul>
<li><p>Last month the Surge conference happened (http://omniti.com/surge/2012) with a lot of goodies. This week the videos were published and there&#8217;s lots of good stuff. I can highlight two examples (not that the other are not good):</p>

<p>  <a href="http://omniti.com/surge/2012/speakers/bergman_artur">Arthur Bergman and Mysteries of a CDN explained (Fastly)</a></p>

<p>  <a href="http://omniti.com/surge/2012/speakers/canahuati_pedro">Pedro Canahuati and Operating at Scale (Facebook)</a></p></li>
<li><p>A distributed counter from basho, presented at <a href="http://basho.com/community/ricon2012/">RICON</a>: <a href="https://github.com/basho/riak_dt">riak_dt</a>. I think the videos are on the way. I&#8217;ve watched it through live streaming. Good stuff all around.</p></li>
<li><p>Still on conferences, it seems like <a href="http://monitorama.com/#speakers">Monitorama</a> will be interesting. There&#8217;s lot on monitoring to be said - less on tools more on doing the smart things. (This presentation )[https://speakerdeck.com/u/obfuscurity/p/the-state-of-open-source-monitoring] from @obfuscurity is a great review and starting point. Fuck nagios.</p></li>
<li><p>Make sure to review (Agile Data)[http://ofps.oreilly.com/titles/9781449326265/index.html] from Russel Jurney - although I always associeate &#8220;Agile&#8221; with bikeshedding this is only on the title and the book means it. From Chapter 2 on you will find practical examples on data analysis. The pieces on email are very interesting.</p></li>
<li><p>Sketching data structures are summaries of structures that otherwise would take a lot of space/time to process. <a href="http://lkozma.net/blog/sketching-data-structures/">This review</a> takes on Bloom Filters and Count-Min structures in a very clear manner. Be the smart guy in your local bikeshedding meeting by throwing away a &#8220;well we&#8217;ve had webscale data so I&#8217;ve reimplemented my indexes as count-min just for fun&#8221;.</p></li>
<li><p>A series from Performance Dynamics on Little&#8217;s Law and I/O performance <a href="http://perfdynamics.blogspot.com.br/2012/08/littles-law-and-io-performance.html">here</a> and <a href="http://perfdynamics.blogspot.com.br/2012/01/throughput-delay-curves.html">here</a> plus a piece on <a href="http://perfdynamics.blogspot.com.br/2010/03/bandwidth-vs-latency-world-is-curved.html">bandwidth vs latency</a>. Let&#8217;s get educated.</p></li>
<li><p>A piece on <a href="http://markorodriguez.com/2011/09/22/a-graph-based-movie-recommender-engine/">graph based recommendation engine</a> using neo4j. Worth the exercise, this might help on event correlation too (same principle but diff techniques to relate cluster of data).</p></li>
<li><p><a href="http://notes.ceondo.com/mongrel2-zmq-paas/">A private PaaS with Mongrel2 and ZeroMQ</a> odd but very complete. I&#8217;ve tried with mixed results but can see the reasoning on extending mongrel2 to do it.</p></li>
<li><p>Still on PaaS <a href="http://blog.nonuby.com/blog/2012/07/02/what-happens-when-you-push-to-heroku/">What happens when you push to heroku</a> and <a href="https://github.com/openruko/">openruko github repo</a> are full of awesome by @nonuby</p></li>
<li><p><a href="https://github.com/dotcloud/hipache">hipache</a> is a http and ws proxy/router. These things are the heart of a PaaS. I&#8217;d love to see it as a nginx module. It&#8217;s doable with openresty but involves lua and other modules. From the great @dotcloud team.</p></li>
<li><p>We&#8217;ve started this year a series of techtalks at (http://www.locaweb.com.br) to spread the knowledge and create a sense of community inside the company. <a href="https://github.com/mediacore/mediacore-community">Mediacore</a> was our platform of choice to manage the videos. Yeah, create your own youtube etc.</p></li>
<li><p>Jeez I dont even&#8230;. <a href="http://browserver.org/">browserver</a> - it works, but oh god why :D nice code and concept, I wish it was torrent so we could p2p between browsers nearby.</p></li>
</ul>


<p>Keep tuned. This list is bound to get back as soon as I clog my browser with tabs again ((anytime between one weekend/2 weeks)). Cheers.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Porting an app from Tornado to Cyclone (quick defer.inlineCallbacks/yield primer)]]></title>
    <link href="http://gleicon.github.com/blog/2012/07/22/porting-an-app-from-tornado-to-cyclone/"/>
    <updated>2012-07-22T21:38:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/07/22/porting-an-app-from-tornado-to-cyclone</id>
    <content type="html"><![CDATA[<p>Note: This will probably turn out in a screencast some time or another.</p>

<p>To port an app from <a href="http://tornadoweb.org">Tornado</a> to <a href="http://cyclone.io">Cyclone</a> is an easy task. There are some quirks tho related to Twisted mainly. This is necessary so you can enjoy the environment and async drivers in a proper manner. Tornado is know to provide good abstractions so you can use regular drivers to hook into its IOLoop. But as event loop goes, most of them requires that the whole stack is aware of the cooperative nature between its components. By using twisted you already have that and bundled with cyclone you have Redis, MongoDB, SQLite and other drivers for applications and protocols.</p>

<p>I&#8217;ve found a neat app called <a href="https://github.com/kumarnitin/RedisLive">RedisLive</a> and ported it to cyclone. It is basically a Redis real time resource monitor composed of two parts: a web interface and a daemon to collect data.</p>

<p>To keep it simple and within a reasonable ammount of code to be explained I&#8217;ve just ported the web interface and created a separated data provider. I&#8217;ve started a twisted based metric collector that helped me to fix and add some missing pieces to cyclone redis driver but I wanted to stick with the original collector.</p>

<p>I&#8217;ll walk out the main parts that were changed. The forked repository is at (my github)[https://github.com/gleicon/RedisLive]. There&#8217;s a full diff file inside my project.</p>

<p>A good approach to port a web application from Tornado to Cyclone is to tackle the web section, and this is what I did. Inside the folder RedisLive/src/api/controller lives the Controllers for each route listed at RedisLive/src/redis-live.py. So starting by redis-live.py:</p>

<pre><code>diff --git a/src/redis-live.py b/src/redis-live.py
index 43479f4..9318c35 100755
--- a/src/redis-live.py
+++ b/src/redis-live.py
@@ -1,8 +1,8 @@
 #! /usr/bin/env python

-import tornado.ioloop
-import tornado.options
-import tornado.web
+from twisted.internet import reactor
+import cyclone.options
+import cyclone.web

 from api.controller.BaseStaticFileHandler import BaseStaticFileHandler

@@ -15,7 +15,7 @@ from api.controller.TopKeysController import TopKeysController


 # Bootup
-application = tornado.web.Application([
+application = cyclone.web.Application([
   (r"/api/servers", ServerListController),
   (r"/api/info", InfoController),
   (r"/api/memory", MemoryController),
@@ -27,6 +27,6 @@ application = tornado.web.Application([


 if __name__ == "__main__":
-   tornado.options.parse_command_line()
-   application.listen(8888)
-   tornado.ioloop.IOLoop.instance().start()
+  cyclone.options.parse_command_line()
+  reactor.listenTCP(8888, application, interface="127.0.0.1")                 
+  reactor.run()
</code></pre>

<p>Basically it turned into a simple twisted application (not a TAC tho). I&#8217;ve changed package names from tornado.* to cyclone.* and switched from tornado.ioloop to reactor.listenTCP()/reactor.run(). The routing and class structure is the same as we are going to see in the Controllers. Most of the changes are package change (from tornado.web to cyclone.web) and by surrounding the drivers call with yield/defer.inlineCallbacks/defer.returnValue.</p>

<p>The regular way to call a method or function according to the twisted way(tm) is that you receive a Deferred class, in which you attach a callback for success and another for error. By using defer.* and yield code gets more readable without that many callbacks following each external call. The downside is that while you are using this decorator and returnValue, your function returns generators so it gets incompatible with normal functions. So you end up structuring your code around it to save time and in some places you got to stick to regular callbacks to make it compatible to libraries that are ported from a non-twisted code. Bikeshedding apart, is a good resource that Twisted provides.</p>

<pre><code>diff --git a/src/api/controller/BaseStaticFileHandler.py b/src/api/controller/BaseStaticFileHandler.py
index 162fa62..6343a53 100644
--- a/src/api/controller/BaseStaticFileHandler.py
+++ b/src/api/controller/BaseStaticFileHandler.py
@@ -1,6 +1,6 @@
-import tornado.web
+import cyclone.web

-class BaseStaticFileHandler(tornado.web.StaticFileHandler):
+class BaseStaticFileHandler(cyclone.web.StaticFileHandler):
    def compute_etag(self):
        return None
</code></pre>

<p>In this case we didn&#8217;t need to change anything beyond module names. Now a bit of defer/yield:</p>

<pre><code>diff --git a/src/api/controller/CommandsController.py b/src/api/controller/CommandsController.py
index cd9df26..ac046e3 100644
--- a/src/api/controller/CommandsController.py
+++ b/src/api/controller/CommandsController.py
@@ -1,12 +1,12 @@
 from BaseController import BaseController
-import tornado.ioloop
-import tornado.web
 import dateutil.parser
 from datetime import datetime, timedelta
+from twisted.internet import defer


 class CommandsController(BaseController):

+    @defer.inlineCallbacks
     def get(self):
         """Serves a GET request.
         """
@@ -45,7 +45,7 @@ class CommandsController(BaseController):
           group_by = "second"

         combined_data = []
-        stats = self.stats_provider.get_command_stats(server, start, end,
+        stats = yield self.stats_provider.get_command_stats(server, start, end,
                                                       group_by)
         for data in stats:
             combined_data.append([data[1], data[0]])
</code></pre>

<p>Note that before the &#8220;get&#8221; method we&#8217;ve added this decorator. If you are using other cyclone decorators, make sure this is the first one (for example if you are using cyclone.web.authenticated and so on). also when using the stats_provider, the call got prepended by yield so the decorator can capture the callback result and make it available to the variable stats without needing an explicit callback (stats = self.stats_provider(&#8230;).addCallback(lambda r: do_something(r))).</p>

<p>The rest of diff is at the repository, lets examine the redis stats provider. To be able to keep the original data collector I&#8217;ve cloned RedisLive/src/dataprovider/redisprovider.py into txredisprovider.py. Cyclone comes with txredisapi bundled as a package and I&#8217;ve wanted to use w/o having to rewrite all the calculation code. Ideally I&#8217;d have changed the whole class and collector. Most of the changed were addition of yield/defer.inlineCallbacks and specifics of cyclone drivers as transactions (started by driver.multi() instead of pipeline).</p>

<p>It was a quick job spread over two days (1h/2h each day) to have RedisLive working with cyclone, including the twisted part. Twisted is a very mature framework and it&#8217;s worth knowing the protocols it already provides. Also, the provided reactors and task primitives (look into redis-monitor-tx.tac) are useful to split heavy work into small tasks.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python and GEvent]]></title>
    <link href="http://gleicon.github.com/blog/2012/06/07/python-and-gevent/"/>
    <updated>2012-06-07T23:36:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/06/07/python-and-gevent</id>
    <content type="html"><![CDATA[<p>The last post took some time over <a href="http://cyclone.io">cyclone</a> and it wasn&#8217;t fair that I&#8217;ve mentioned gevent briefly. I&#8217;ve have been using this library both for quick prototypes, production code and system upgrades. It&#8217;s not an instant-evented-magic-to-crappy-code but it provides simple and solid primitives such as greenlets that enable the use of good libraries in a fashion manner.</p>

<p>For instance, the great kombu library, which provides abstraction over different messaging protocols is not available to twisted. Worst yet, the txAMQP library is not straight forward to use. At the <a href="http://github.com/gleicon/mure">mure</a> project I wanted to come with a quick and simple agent network that communicated for a shared bus. I wasn&#8217;t worried about which kind of channel as long as I could prototype and run it quickly. It proved good because in short time I&#8217;ve implemented an EventEmitter clone inspired on node.js and a few days ago a bridge between python and node.js event emitters.</p>

<p>It could be done using twisted but I would have to shave the yak related to a common multi broker messaging or stick to a single message broker. Not a problem if I had it clear from the start what I wanted it to be. But having gevent helped a lot to leverage the common blocking libraries and to use greenlets as a thread abstraction.</p>

<figure class='code'><figcaption><span>mure/core.py </span><a href='https://github.com/gleicon/mure/blob/master/mure/core.py#L19-37'>link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'>    <span class="k">def</span> <span class="nf">add_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">workername</span><span class="p">,</span> <span class="n">callback</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">[</span><span class="n">workername</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>
</span><span class='line'>        <span class="k">def</span> <span class="nf">_listener</span><span class="p">():</span>
</span><span class='line'>            <span class="n">qname</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">(</span><span class="n">workername</span><span class="p">,</span> <span class="n">Exchange</span><span class="p">(</span><span class="s">&quot;exchange:</span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">workername</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s">&#39;fanout&#39;</span><span class="p">))</span>
</span><span class='line'>            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connected</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span>
</span><span class='line'>                <span class="k">print</span> <span class="s">&quot;waiting </span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connected</span>
</span><span class='line'>                <span class="n">gevent</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>            <span class="k">with</span> <span class="n">BrokerConnection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_transport_url</span><span class="p">)</span> <span class="k">as</span> <span class="n">conn</span><span class="p">:</span>
</span><span class='line'>                <span class="k">with</span> <span class="n">conn</span><span class="o">.</span><span class="n">SimpleQueue</span><span class="p">(</span><span class="n">qname</span><span class="p">)</span> <span class="k">as</span> <span class="n">queue</span><span class="p">:</span>
</span><span class='line'>                    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class='line'>                        <span class="k">try</span><span class="p">:</span>
</span><span class='line'>                            <span class="n">message</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span class='line'>                            <span class="k">if</span> <span class="n">message</span><span class="p">:</span>
</span><span class='line'>                                <span class="bp">self</span><span class="o">.</span><span class="n">_execute_callbacks</span><span class="p">(</span><span class="n">workername</span><span class="p">,</span> <span class="n">message</span><span class="o">.</span><span class="n">payload</span><span class="p">)</span>
</span><span class='line'>                                <span class="n">message</span><span class="o">.</span><span class="n">ack</span><span class="p">()</span>
</span><span class='line'>                                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_connected</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span> <span class="k">break</span>
</span><span class='line'>                        <span class="k">except</span><span class="p">:</span>
</span><span class='line'>                            <span class="k">pass</span>
</span><span class='line'>        <span class="n">gevent</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">_listener</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The last line spawn the function <em>_listener</em> which binds into an exchange queue. Each of these listeners take care of a communication channel and execute the callbacks associated to that worker name. Exchange, queue, worker are the samething applied in different contexts. These workers (@worker(&#8216;name_of_worker&#8217;)) are stored in a hash, each item a list of listeners. This spans out the messages around the right recipients.</p>

<p>Another great gevent companion is <a href="http://bottlepy.org/">bottle</a>, a DSL for web programming. Its interface is clean and combining with gevent lets you quickly come with thin webservices interfaces. I&#8217;ve create an application called <a href="https://github.com/gleicon/uurl">uurl</a> - an url shortener, entirely based on gevent, bottle and readis. I&#8217;ve set to rewrite it from time to time, on different languages and frameworks to get a hang of their components and so far this is the cleanest implementation. It started as an WSGI service and later I&#8217;ve converted to gevent by simply changing servers, monkey patching all and using a redis connection pool.</p>

<p>Monkey patching is a technique that bottle uses to convert the original socket, threads and other python modules to be non-blocking using its greenlets and I/O loop, in a way that the code change is minimal from a blocking application.</p>

<figure class='code'><figcaption><span>uurl.py </span><a href='https://github.com/gleicon/uurl/blob/master/uurl.py#L120-125'>link</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">GEventServerAdapter</span><span class="p">(</span><span class="n">ServerAdapter</span><span class="p">):</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">handler</span><span class="p">):</span>
</span><span class='line'>        <span class="kn">from</span> <span class="nn">gevent</span> <span class="kn">import</span> <span class="n">monkey</span>
</span><span class='line'>        <span class="n">monkey</span><span class="o">.</span><span class="n">patch_socket</span><span class="p">()</span>
</span><span class='line'>        <span class="kn">from</span> <span class="nn">gevent.wsgi</span> <span class="kn">import</span> <span class="n">WSGIServer</span>
</span><span class='line'>        <span class="n">WSGIServer</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">host</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">port</span><span class="p">),</span> <span class="n">handler</span><span class="p">)</span><span class="o">.</span><span class="n">serve_forever</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>To close this post, I&#8217;d like to add that I usually compare this setup with Ruby/Sinatra/Thin. As a derivative of <a href="http://restmq.com">RestMQ</a> I&#8217;ve created <a href="https://github.com/gleicon/tinymq">TinyMQ</a> - a set of small implementations of RestMQ core ideas. This is a subject for another post but the whole message broker ran on less than 100 lines <a href="https://github.com/gleicon/tinymq/blob/master/python/tinymq.py">tinymq.py</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cyclone - a twisted based Tornado implementation]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/15/cyclone-a-twisted-based-tornado-implementation/"/>
    <updated>2012-03-15T23:21:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/15/cyclone-a-twisted-based-tornado-implementation</id>
    <content type="html"><![CDATA[<h3>Overview</h3>

<p>Some time ago, a company called FriendFeed released <a href="http://www.tornadoweb.org/">Tornado</a>, a neat web application server for python. After some press and unquestionable results it was discussed whether it should have used the Twisted Framework foundation instead of implementing a new ioloop. Long history short, Tornado shares some similarities with <a href="http://twistedmatrix.com/trac/">Twisted</a>, but the programming API is better looking than twisted.web.</p>

<p>After some trials by different people <a href="http://github.com/fiorix">Alex Fiori</a> forked Tornado and bundled it with a Twisted backend and some other goodies - calling it <a href="http://cyclone.io">cyclone</a>. After a while I started using it to build <a href="http://restmq.com">RestMQ</a> and started contributing code for WebSockets and other drivers. There is a lot of sense in combining both worlds as Twisted has an extensive ibrary of protocols and clients, a well defined programming model (like it or not, based on deferreds/futures and generators) and mature cross-platform ioloop implementation. Cyclone&#8217;s gettext implementation was merged back some time in the past and we constantly merge from upstream on interesting features.</p>

<p>I do most of my coding in python splitting time between cyclone and gevent and right now I gotta say that cyclone has great features that compete in terms of productivity with Tornado.</p>

<p>Code that is build on tornado will run easily after correcting the package names. On the parts related to ioloop, there are the same mapped functionality on twisted - such as timers and pools. To build new protocols you can leverage LineProtocol and other interesting tx classes. The best part is taking advantage of drivers. In an evented loop, if you use a regular driver that can block (pause while waiting for an answer from network or heavy calculation) the other operations are also halted.</p>

<p>If you have a defined programming model to deal with it (which both tornado and twisted defined), it is a matter of yielding at the right moment or using a deferred return to realize the result of the operation later. That can lead to a kind of callback hell both for reading code and profiling it but there are few abstractions that will go far away from it.</p>

<h3>Interesting Cyclone features</h3>

<p><img src="images/cyclone_arch.png" title="Cyclone Architecture" ></p>

<p>Tornado core (ioloop) was changed by a twisted based factory which yield the right reactor. Over this structure the protocol implementation and clients were adapted to use it with minimal to none interface changes.</p>

<p>The most affected module initially was cyclone.web but the whole structure changed and got bundled drivers as mongodb, redis, sqlite and protocols as XMLRPC, JSONRPC, websockets and sse. There is an email module already which can serve as template-to-message app, based on TwistedMail. All these features are natively asynchronous.</p>

<p>Beyond that, a cyclone app is a twisted protocol and can take advantage of the surrounding structure as plugins and PyDirector/cpu affinity. It was easy to merge or create due to the synergy based on already existing twisted applications. There is also an application skeleton and a minimal bottle.py DSL port - both allowing for quickstart web applications.</p>

<p>Much of the authentication and authorization is done over decorators, allowing for clean code - along with the inline deferreds:</p>

<pre><code>class IndexHandler(cyclone.web.RequestHandler):
    @cyclone.web.authenticated  # triggers authentication
    @defer.inlineCallbacks      # allows for inline callbacks
    def get(self):
        result = yield self.do_download()  # inline callback, no need to explicitly added 
        self.write(result)
</code></pre>

<p>That alone may help on the callback spaghetti but it keeps being twisted.</p>

<h3>Evented I/O intermission - is it faster ?</h3>

<p>No. It&#8217;s just a choice of multiplexer to allow for better time utilization. It helps scaling better the same resources as other approaches such as greenlets over an evented loop (gevent). The most important thing to note is that they are not a substitute for threads of VM limitations. My setups usually are 1 or 2 instances per core, with affinity and a load balance in front of them. This can be done in a different manner as using threadpools or even processes.</p>

<p>Last year I presented at Sao Paulo Perl Workshop and OSCon on this subject and the feedback that I got is that most of the time the very application gets complex so the matter of evented I/O ends up being one of the things that shapes these changes (for good or bad) but not the safeguard or guarantee that the quality will keep up.</p>

<div class="embed rich SlideShare"><iframe src="http://www.slideshare.net/slideshow/embed_code/7883101" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="http://www.slideshare.net/gleicon/architecture-by-accident" title="Architecture by Accident" target="_blank">Architecture by Accident</a> </strong> from <strong><a href="http://www.slideshare.net/gleicon" target="_blank">gleicon</a></strong> </div></div>




<div class="embed rich SlideShare"><iframe src="http://www.slideshare.net/slideshow/embed_code/8728812" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="http://www.slideshare.net/gleicon/oscon-performance-vs-scalability" title="OSCon - Performance vs Scalability" target="_blank">OSCon - Performance vs Scalability</a> </strong> from <strong><a href="http://www.slideshare.net/gleicon" target="_blank">gleicon</a></strong> </div></div>


<h3>EOF</h3>

<p>Check the <a href="https://github.com/fiorix/cyclone">code</a> and try it for yourself. I consider that using cyclone is a good and gentle intro to twisted as it sets a clear objective over web applications. There are plenty of good code at the demos directory and the app skeleton already comes up with a bootstrap.css based application boilerplate. Also, send patches.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On that message queue...]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/07/on-that-message-queue-dot-dot-dot/"/>
    <updated>2012-03-07T06:21:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/07/on-that-message-queue-dot-dot-dot</id>
    <content type="html"><![CDATA[<p>&#8230;that you are trying to do with Redis, the answer is NO.</p>

<p>Not by any issue with <a href="http://redis.io">Redis</a> (which I use in a lot of projects and it&#8217;s a fine piece of software), but because the primitives are not enough to pass as a message broker.</p>

<p>Looking to Redis and <a href="http://www.zeromq.org">ZeroMQ</a> as a message broker in the classic ActiveMQ/RabbitMQ/RestMQ sense is naive, because both are transports (and in Redis case, persistence sometimes) and building blocks that can be attached to systems like these and libraries..</p>

<p>The regular drivers for Redis usually provides no reconnection in case of error or subscribe disconnect, so you probably might end up having your process hanging or if you are lucky, killed with an exception in case of a lost connection. The proper way to do it is to surround Redis with a management layer, as <a href="http://restmq.com">RestMQ</a> or Resque does.</p>

<p>An interesting approach taken on the <a href="https://github.com/fiorix/txredisapi/">twisted redis client</a> is to make use of connection pools which can reconnect. That was the single feature that made RestMQ possible. <a href="https://github.com/ask/kombu">Kombu</a> connections follow the same pattern, abstracting fan outs and routes over a connection pool to Redis, the simples fallback in case you dont want to install any other complex message broker.</p>

<p>Applying only to pub/sub channels without fallback is not a good idea specially if you rely on multiple consumers. On the other hand, for simple one-time no-distributed-locks messaging (as with udp multicas or service discovery), it might be a good choice because: a) there is no persistence and b) if the transport is not available, the processes(or agents) are idle.</p>

<p>The fine line here is the direction of the messages. In a exchange environment, the broker plays the good part of managing the transport shortcomings. On a fire and forget which the messages are importante, the broker helps to keep the message somewhere until it&#8217;s fetched. Fire and forget of disposable messages might be a good choice to do it if there is no immediate action to be taken and if there is some kind of retransmission/expiring on the sender part. Remember the SMTP protocol.</p>

<p>That&#8217;s not even touching the cases where a message queue is used as a kind of distributed lock where only one of many similar consumers might get a message, instead of a broadcast scenario.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[memcached backend engines]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/06/memcached-backend-engines/"/>
    <updated>2012-03-06T14:31:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/06/memcached-backend-engines</id>
    <content type="html"><![CDATA[<p>The memcached protocol is very known and implemented on many languages and frameworks. Its primitives are based around getting and setting values that internally are mapped to keys.</p>

<p>There are two kinds of protocol: ascii and binary. The recommended protocol is the binary protocol, which is modern and has room for new features.</p>

<p>I&#8217;ve been trying my hand at some memcached servers implementations in python, based on twisted and gevent, but looking for some answers regarding the protocol answer, I got a tip that the original memcached server is supporting backend engines through an ANSI C interface. In an insomniac week end I was able to hack around two examples: a filesystem based store and a redis based store.</p>

<p>The <a href="https://github.com/gleicon/memcached_fs_engine">filesystem engine</a> was based entirely on @trondn <a href="http://trondn.blogspot.com/2010/10/writing-your-own-storage-engine-for.html">tutorial</a>. <a href="https://github.com/gleicon/memcached_redis_engine">The Redis engine</a> I made based on my original plan for a <a href="https://github.com/gleicon/tx-memcached-redis">python based memcached server</a>. I&#8217;ve used Redis&#8217; hashes to store data and attributes for each memcached key.</p>

<p>To create the hash, the engine issues a command like this:</p>

<blockquote><p>HMSET <keyname> key <keyname> nkey <keyname len> data <data> ndata <data len> flags <flags> exptime <expiration time, if any></p></blockquote>

<p>The advantage of Redis commands being atomic is that INCR, DECR and methods like this are a given. It was a matter of using hiredis to map the right commands. One thing that I&#8217;d do differently is to implement a kind of connection pool and configuration options.</p>

<p>To test the backend compliance to the binary protocol I&#8217;ve used <em>memcapable</em>, which usually comes bundled with memcached. The engine must be compiled as a dynamic library so it can be loaded as memcached -E engine.so.</p>

<p>One of the things that I think that having a configurable memcached frontend is good for is to capture metrics. As many frameworks already have a memcached client, it&#8217;s easy to create an instance and increment/decrement counters on it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Agents and Event Listeners for Python]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/04/agents-and-event-listeners-for-python/"/>
    <updated>2012-03-04T19:03:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/04/agents-and-event-listeners-for-python</id>
    <content type="html"><![CDATA[<p>When modeling a distributed system one might stumble in the Actor model, implemented in one way or another - be it natively on Erlang or a complete library as Akka.</p>

<p>There is a lot of discussion over concurrency models, but regardless the Actor model serves well to break a task between different processes/servers.</p>

<p>Built usually over a messaging channel, these frameworks are usually adapted for a set of tasks.
As it wouldn&#8217;t be different, some of them had a lot more than I needed, and the frameworks for Python were divided between trying to reimplement Akka or completely different concept.</p>

<p>I took some time out to build <a href="http://github.com/gleicon/mure">Mure</a> to learn more about kombu, a multi-transport library for python. It&#8217;s a really simple actor library.</p>

<div><script src='https://gist.github.com/1975450.js?file='></script>
<noscript><pre><code>   from mure.core import connect, disconnect, worker, send_message             
    from time import sleep                                                      
                                                                                
    @worker('/workers/delicious')                                               
    def a_worker(message):                                                      
        print &quot;received: %s&quot; % message                                          
        send_message('/workers/jazz', 'd-d-d-dance')                            
                                                                                
    @worker('/workers/jazz')                                                    
    def another_worker(message):                                                
        print &quot;received2: %s&quot; % message                                         
        send_message('/workers/delicious', &quot;saaaap&quot;)                            
                                                                                
    @worker('/workers/delicious')                                               
    def third_worker(message):                                                  
        print &quot;the other worker received: %s&quot; % message                         
                                                                                
    if __name__ == &quot;__main__&quot;:                                                  
        connect()                                                               
        send_message('/workers/jazz', 'let it start')                           
        sleep(1)                                                                
        disconnect()      </code></pre></noscript></div>


<p>The decorator @worker() says that each time that a message to the queue named after the string arrives, the function might be executed having the message as parameter.</p>

<p><img src="images/mure_architecture.png" title="Architecture for Mure" ></p>

<p>After fidling with <a href="https://github.com/jesusabdullah/pyee">pyee</a>, I&#8217;ve implemented an EventEmitter on top of it. The syntax is the same as node.js, but it&#8217;s a distributed event emitter.</p>

<div><script src='https://gist.github.com/1975438.js?file='></script>
<noscript><pre><code>from mure.dee import DistEventEmitter                                                                                                                                             
import os, json, time                                                           
from gevent import sleep, spawn                                                 
                                                                                
dbus = DistEventEmitter()                                                       
                                                                                
def producer():                                                                 
    count =0                                                                    
    while(True):                                                                
        count = count +1                                                        
        print count                                                             
        dbus.emit(&quot;message&quot;, &quot;hnam %d&quot; % count)                                 
        sleep(5)                                                                
                                                                                
                                                                                
def join_listener(msg):                                                         
    print &quot;%s&quot; % msg                                                            
                                                                                
def msg_listener(msg):                                                          
    print &quot;received message: %s&quot; % msg                                          
                                                                                
def main():                                                                     
    dbus.emit('join', &quot;oeam&quot;)                                                   
    dbus.on('message', msg_listener)                                            
    producer()                                                                  
                                                                                
if __name__ == &quot;__main__&quot;:                                                      
    main()</code></pre></noscript></div>


<p><img src=http://localhost:8080/track?_id=1 width=1 height=1></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Riemann client for python]]></title>
    <link href="http://gleicon.github.com/blog/2012/03/04/reimann-client-for-python/"/>
    <updated>2012-03-04T18:34:00-03:00</updated>
    <id>http://gleicon.github.com/blog/2012/03/04/reimann-client-for-python</id>
    <content type="html"><![CDATA[<p>In the search for the right backend to implement a metrics suited to my projects, I saw that <a href="http://aphyr.github.com/riemann">Riemann</a> (event server built on Closure) would save time by already having all kinds of math related to means, percentiles and a flexible configuration.</p>

<p>The protocol uses Google&#8217;s Protocol Buffers, but it&#8217;s very simple (I was able to go from 0 to a simple driver in less than 4 hours - including the protobuf part).
Basic functionality as sending metrics and querying are ready, but the driver still needs polishing - include a connection pool, and a twisted version. As it is right now, it works great with gevent apps.</p>

<p>A basic send/query app would be like this:</p>

<div><script src='https://gist.github.com/1975656.js?file='></script>
<noscript><pre><code>from riemann import RiemannClient                                                                                                                                                 
                                                                                
def main():                                                                     
    rc = RiemannClient()                                                        
    rc.send({'host':'127.0.0.1', 'service': 'www', 'state': 'down', 'metric_f': 10000})
    res = rc.query('host')                                                      
    print res                                                                   
    for e in res.events: print e.host                                           
                                                                                
if __name__ == '__main__':                                                      
    main()     </code></pre></noscript></div>


<p>It supports both tcp and udp transports and includes the proper classes translated from protobuf spec to python. Requires google&#8217;s protobuf library. The repo is on github <a href="https://github.com/gleicon/pyriemann">pyriemann</a>. There is an examples directory with riemann_health.py, translated from the ruby version to python.</p>
]]></content>
  </entry>
  
</feed>
